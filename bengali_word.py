# -*- coding: utf-8 -*-
"""bengali_word

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PnvvfLNaoOLbEldH_rBMFejXFRoNA1vn
"""

#from google.colab import drive
#drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import os
import glob
import cv2
from matplotlib import pyplot as plt
from keras import utils as np_utils
from keras.utils import to_categorical
from keras.optimizers import RMSprop
from keras.layers import LSTM, Dense, Dropout
from keras.layers import Dense, Input, Conv1D, Flatten, MaxPooling1D, Activation,Dropout,BatchNormalization
from keras.models import Sequential
import pandas as pd 
import numpy as np 
import keras

bengalichar = {"া" : 100,
               "ি" : 150,
               "ী" : 200,
               "ু" : 250,
               "ূ" : 300,
               "ৃ" : 350,
               "ে" : 400,
               "ৈ" : 450,
               "ো" : 500,
               "ৌ" : 550,
               "ং" : 600,
               "ঃ" : 650,
               "ঁ" : 700,
               "অ" : 1,
               "আ" : 2,
               "ই" : 3,
               "ঈ" : 4,
               "উ" : 5,
               "ঊ" : 6,
               "ঋ" : 7,
               "এ" : 8,
               "ঐ" : 9,
               "ও" : 10,
               "ঔ" : 11,
               "ক" : 21,
               "খ" : 22,
               "গ" : 23,
               "ঘ" : 24,
               "ঙ" : 25,
               "চ" : 26,
               "ছ" : 27,
               "জ" : 28,
               "ঝ" : 29,
               "ঞ" : 30,
               "ট" : 31,
               "ঠ" : 32,
               "ড" : 33,
               "ঢ" : 34,
               "ণ" : 35,
               "ত" : 36,
               "থ" : 37,
               "দ" : 38,
               "ধ" : 39,
               "ন" : 40,
               "প" : 41,
               "ফ" : 42,
               "ব" : 43,
               "ভ" : 44,
               "ম" : 45,
               "য" : 46,
               "র" : 47,
               "ল" : 48,
               "শ" : 49,
               "ষ" : 50,
               "স" : 51,
               "হ" : 52,
               "ড়" : 53,
               "ঢ়" : 54,
               "য়" : 55,
               "ৎ" : 56
              }

def to_label(y):
  y_label = []
  for i in y:
    l = list(i)
    val = 0
    for j in l:
      val = val + bengalichar[j]
    y_label.append(val)
  print("Labeled {}/{}".format(len(y_label), len(y)))
  return y_label

def get_key(path):
    # seperates the key of an image from the filepath
    key=path.split(sep=os.sep)[-1]
    return key

def get_data(paths_img, path_label=None):
  X = []
  data_dir = 'C:\Desktop\bengalidataset'
  paths_img = glob.glob(os.path.join(data_dir, paths_img,'*.png'))
  for i, path in enumerate(paths_img):
    img = cv2.imread(path)
    img = np.float32(img)
    img=cv2.resize(img,(128,128), interpolation=cv2.INTER_AREA)
    #removing blur
    gaussian = cv2.GaussianBlur(img, (3, 3), 0)
    img = cv2.addWeighted(img, 1.5, gaussian, -0.5, 0, img)
    #plt.imshow(img)
    #plt.show()
    X.append(img)

    #display progress
    if (i==len(paths_img)-1):
      print('processed {}/{}'.format(i+1,len(paths_img)))
    
  X = np.array(X)
  if (path_label is None):
    return X
  else:
    #read labels
    path_label = os.path.join(data_dir, path_label)
    df = pd.read_csv(path_label) 
    df = df.set_index('filename')
    #get the labels corresponding to the images
    y = [df.loc[get_key(path)]['word'] for path in  paths_img] 
    y = to_label(y)
    y=to_categorical(y,1000)
    return X, y

X_train, y_train = get_data('training', 'training.csv')
X_test, y_test = get_data('test', 'test.csv')

X_train.shape

X_train = X_train[:, :, :, 0]
X_train.shape

X_test = X_test[:, :, :, 0]
X_test.shape

batch_size = 128
input_shape = (128, 128)
nb_lstm_outputs = 30
nb_classes = 3
#Buliding RNN Model
model = Sequential()
model.add(LSTM(nb_lstm_outputs, input_shape=input_shape, activation='relu', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(512, return_sequences=False))
model.add(Dropout(0.3))
model.add(Dense(1000, activation='softmax'))
optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=10, 
                    batch_size=batch_size,
                    validation_data = (X_test, y_test),
                    shuffle=True, verbose=1)

from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier(hidden_layer_sizes=(20, 5), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)

mlp.fit(X_train, y_train)

model = Sequential()
model.add(Dense(512, activation='relu', input_shape = (128, 128)))
model.add(Dense(512))
model.add(Dense(1000, activation='softmax'))
optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

batch_size = 128
history = model.fit(X_test, y_test, epochs=10, 
                    batch_size=batch_size,
                    validation_data = (X_train, y_train),
                    shuffle=True, verbose=1)

input_shape = (128, 128)
batch_size = 128
model = Sequential()
model.add(Conv1D(32, (5), input_shape=input_shape, activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling1D(pool_size=6))
model.add(Flatten())
model.add(Dense(1000, activation='softmax'))
model.add(Dropout(0.2))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')

history = model.fit(X_train, y_train, 
            batch_size=batch_size, 
            epochs=10, 
            verbose=1, 
            validation_data=(X_test, y_test),
            shuffle=True
            )